{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Getting a Satelite Image from Google Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import io\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def get_static_google_map(filename_wo_extension, center=None, zoom=None, imgsize=\"300x300\", imgformat=\"jpeg\",\n",
    "                          maptype=\"satellite\", markers=None ):  \n",
    "    \n",
    "    \"\"\"retrieve a map (image) from the static google maps server \n",
    "    \n",
    "     See: http://code.google.com/apis/maps/documentation/staticmaps/\n",
    "        \n",
    "        Creates a request string with a URL like this:\n",
    "        http://maps.google.com/maps/api/staticmap?center=Brooklyn+Bridge,New+York,NY&zoom=14&size=512x512&maptype=roadmap\n",
    "&markers=color:blue|label:S|40.702147,-74.015794&sensor=false\"\"\"\n",
    "   \n",
    "    \n",
    "    # assemble the URL\n",
    "    request =  \"http://maps.google.com/maps/api/staticmap?\" # base URL, append query params, separated by &\n",
    "    \n",
    "    # if center and zoom  are not given, the map will show all marker locations\n",
    "    if center != None:\n",
    "        request += \"center=%s&\" % center\n",
    "        #request += \"center=%s&\" % \"52.2323,4.53\"   # latitude and longitude (up to 6-digits)\n",
    "        #request += \"center=%s&\" % \"50011\" # could also be a zipcode,\n",
    "        #request += \"center=%s&\" % \"Brooklyn+Bridge,New+York,NY\"  # or a search term \n",
    "    if center != None:\n",
    "        request += \"zoom=%i&\" % zoom  # zoom 0 (all of the world scale ) to 22 (single buildings scale)\n",
    "\n",
    "\n",
    "    request += \"size=%ix%i&\" % (imgsize)  # tuple of ints, up to 640 by 640\n",
    "    request += \"format=%s&\" % imgformat\n",
    "    request += \"maptype=%s&\" % maptype  # roadmap, satellite, hybrid, terrain\n",
    "\n",
    "\n",
    "    # add markers (location and style)\n",
    "    if markers != None:\n",
    "        for marker in markers:\n",
    "                request += \"%s&\" % marker\n",
    "\n",
    "\n",
    "    #request += \"mobile=false&\"  # optional: mobile=true will assume the image is shown on a small screen (mobile device)\n",
    "    request += \"sensor=false&\"   # must be given, deals with getting loction from mobile device \n",
    "    request += \"key=AIzaSyC16u04UOOTLijtJrNpN2PL2HjMl9Ijp3c\"\n",
    "    print(request)\n",
    "    \n",
    "    urllib.request.urlretrieve(request, filename_wo_extension+\".\"+imgformat) # Option 1: save image directly to disk\n",
    "    \n",
    "    # Option 2: read into PIL \n",
    "    web_sock = urllib.request.urlopen(request)\n",
    "    imgdata = io.BytesIO(web_sock.read()) # constructs a StringIO holding the image\n",
    "    try:\n",
    "        PIL_img = Image.open(imgdata)\n",
    "    \n",
    "    # if this cannot be read as image that, it's probably an error from the server,\n",
    "    except IOError:\n",
    "        print(\"IOError:\", imgdata.read()) # print error (or it may return a image showing the error\"\n",
    "     \n",
    "    # show image \n",
    "    else:\n",
    "        PIL_img.show()\n",
    "        #PIL_img.save(filename_wo_extension+\".jpg\", \"JPEG\") # save as jpeg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://maps.google.com/maps/api/staticmap?center=52.350950,4.922501&zoom=19&size=300x300&format=jpg&maptype=satellite&sensor=false&key=AIzaSyC16u04UOOTLijtJrNpN2PL2HjMl9Ijp3c\n"
     ]
    }
   ],
   "source": [
    "# define a series of location markers and their styles\n",
    "# syntax:  markers=markerStyles|markerLocation1|markerLocation2|... etc.\n",
    "marker_list = []\n",
    "marker_list.append(\"markers=color:blue|label:S|11211|11206|11222\") # blue S at several zip code's centers\n",
    "marker_list.append(\"markers=size:tiny|label:B|color:0xFFFF00|40.702147,-74.015794|\") # tiny yellow B at lat/long\n",
    "marker_list.append(\"markers=size:mid|color:red|label:6|Brooklyn+Bridge,New+York,NY\") # mid-sized red 6 at search location\n",
    "# see http://code.google.com/apis/maps/documentation/staticmaps/#Markers\n",
    "\n",
    "\n",
    "# make a map around a center\n",
    "get_static_google_map(\"google_map_example1\", center=\"52.350950,4.922501\", zoom=19, imgsize=(300,300), imgformat=\"jpg\", maptype=\"satellite\" )\n",
    "\n",
    "\n",
    "#get_static_google_map(\"google_map_example2\", center=\"Keukenhof\", zoom=18, imgsize=(500,500), maptype=\"hybrid\")\n",
    "\n",
    "\n",
    "# make map that shows all the markers\n",
    "#get_static_google_map(\"google_map_example3\", imgsize=(640,640), imgformat=\"png\", markers=marker_list )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\pycocotools\\coco.py:49: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\asyncio\\events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-f2981f6885c7>\", line 5, in <module>\n",
      "    import skimage.io\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\skimage\\io\\__init__.py\", line 15, in <module>\n",
      "    reset_plugins()\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\skimage\\io\\manage_plugins.py\", line 95, in reset_plugins\n",
      "    _load_preferred_plugins()\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\skimage\\io\\manage_plugins.py\", line 75, in _load_preferred_plugins\n",
      "    _set_plugin(p_type, preferred_plugins['all'])\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\skimage\\io\\manage_plugins.py\", line 87, in _set_plugin\n",
      "    use_plugin(plugin, kind=plugin_type)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\skimage\\io\\manage_plugins.py\", line 258, in use_plugin\n",
      "    _load(name)\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\skimage\\io\\manage_plugins.py\", line 302, in _load\n",
      "    fromlist=[modname])\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py\", line 4, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\matplotlib\\pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"C:\\Users\\ioann\\AppData\\Local\\conda\\conda\\envs\\apelpisia\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'coco'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f2981f6885c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmaskUtils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcoco\u001b[0m \u001b[1;31m#a slightly modified version\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_coco_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_coco\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'coco'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "\n",
    "# Download and install the Python COCO tools from https://github.com/waleedka/coco\n",
    "# That's a fork from the original https://github.com/pdollar/coco with a bug\n",
    "# fix for Python 3.\n",
    "# I submitted a pull request https://github.com/cocodataset/cocoapi/pull/50\n",
    "# If the PR is merged then use the original repo.\n",
    "# Note: Edit PythonAPI/Makefile and replace \"python\" with \"python3\".\n",
    "#  \n",
    "# A quick one liner to install the library \n",
    "# !pip install git+https://github.com/waleedka/coco.git#subdirectory=PythonAPI\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "import coco #a slightly modified version\n",
    "\n",
    "from mrcnn.evaluate import build_coco_results, evaluate_coco\n",
    "from mrcnn.dataset import MappingChallengeDataset\n",
    "from mrcnn import visualize\n",
    "\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "import glob\n",
    "import tqdm\n",
    "import random\n",
    "#import keras\n",
    "#os.environ['KERAS_BACKEND']='tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the default backend isn't tensorflow\n",
    "import importlib\n",
    "\n",
    "from keras import backend as K\n",
    "from os import environ\n",
    "\n",
    "# user defined function to change keras backend\n",
    "def set_keras_backend(backend):\n",
    "    if K.backend() != backend:\n",
    "        environ['KERAS_BACKEND'] = backend\n",
    "        importlib.reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "# call the function with \"theano\"\n",
    "set_keras_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset location \n",
    "Now we expect that you have downloaded all the files in the datasets section and untar-ed them to have the following structure :\n",
    "```\n",
    "├── data\n",
    "|   ├── pretrained_weights.h5 (already included in this repository)\n",
    "│   ├── test\n",
    "│   │   └── images/\n",
    "│   │   └── annotation.json\n",
    "│   ├── train\n",
    "│   │   └── images/\n",
    "│   │   └── annotation.json\n",
    "│   └── val\n",
    "│       └── images/\n",
    "│       └── annotation.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantitate Inference Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "\n",
    "PRETRAINED_MODEL_PATH = os.path.join(ROOT_DIR,\"data/\" \"pretrained_weights.h5\")\n",
    "LOGS_DIRECTORY = os.path.join(ROOT_DIR, \"logs\")\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "print(MODEL_DIR)\n",
    "print(PRETRAINED_MODEL_PATH)\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"data\", \"test\", \"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1  # 1 Background + 1 Building\n",
    "    IMAGE_MAX_DIM=320\n",
    "    IMAGE_MIN_DIM=320\n",
    "    NAME = \"crowdai-mapping-challenge\"\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "model_path = PRETRAINED_MODEL_PATH\n",
    "\n",
    "# or if you want to use the latest trained model, you can use : \n",
    "# model_path = model.find_last()[1]\n",
    "\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Prediction on a single Image (and visualize results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['BG', 'building'] # In our case, we have 1 class for the background, and 1 class for building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(IMAGE_DIR)\n",
    "file_names = next(os.walk(IMAGE_DIR))[2]\n",
    "#print(file_names)\n",
    "#random_image = skimage.io.imread(os.path.join(IMAGE_DIR, random.choice(file_names)))\n",
    "random_image = skimage.io.imread('/Users/atholis/Desktop/HMMY/Diploma Thesis/google_map_example1.jpg')\n",
    "print(random_image)\n",
    "\n",
    "predictions = model.detect([random_image]*config.BATCH_SIZE, verbose=1) # We are replicating the same image to fill up the batch_size\n",
    "\n",
    "p = predictions[0]\n",
    "visualize.display_instances(random_image, p['rois'], p['masks'], p['class_ids'], \n",
    "                            class_names, p['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions on all the images in the test set\n",
    "\n",
    "Note that this step might take some time depending on the GPU(s) you have and your system configuration. On a single NVIDIA TitanX it take about 1.25 hours to generate all the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all JPG files in the test set as small batches\n",
    "files = glob.glob(os.path.join(IMAGE_DIR, \"*.jpg\"))\n",
    "ALL_FILES=[]\n",
    "_buffer = []\n",
    "for _idx, _file in enumerate(files):\n",
    "    if len(_buffer) == config.IMAGES_PER_GPU * config.GPU_COUNT:\n",
    "        ALL_FILES.append(_buffer)\n",
    "        _buffer = []\n",
    "    else:\n",
    "        _buffer.append(_file)\n",
    "\n",
    "if len(_buffer) > 0:\n",
    "    ALL_FILES.append(_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all the batches and predict\n",
    "_final_object = []\n",
    "for files in tqdm.tqdm(ALL_FILES):\n",
    "    images = [skimage.io.imread(x) for x in files]\n",
    "    predoctions = model.detect(images, verbose=0)\n",
    "    for _idx, r in enumerate(predoctions):\n",
    "        _file = files[_idx]\n",
    "        image_id = int(_file.split(\"/\")[-1].replace(\".jpg\",\"\"))\n",
    "        for _idx, class_id in enumerate(r[\"class_ids\"]):\n",
    "            if class_id == 1:\n",
    "                mask = r[\"masks\"].astype(np.uint8)[:, :, _idx]\n",
    "                bbox = np.around(r[\"rois\"][_idx], 1)\n",
    "                bbox = [float(x) for x in bbox]\n",
    "                _result = {}\n",
    "                _result[\"image_id\"] = image_id\n",
    "                _result[\"category_id\"] = 100\n",
    "                _result[\"score\"] = float(r[\"scores\"][_idx])\n",
    "                _mask = maskUtils.encode(np.asfortranarray(mask))\n",
    "                _mask[\"counts\"] = _mask[\"counts\"].decode(\"UTF-8\")\n",
    "                _result[\"segmentation\"] = _mask\n",
    "                _result[\"bbox\"] = [bbox[1], bbox[0], bbox[3] - bbox[1], bbox[2] - bbox[0]]\n",
    "                _final_object.append(_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write prediction files to JSON and submit to crowdAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"predictions.json\", \"w\")\n",
    "import json\n",
    "print(\"Writing JSON...\")\n",
    "fp.write(json.dumps(_final_object))\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crowdai\n",
    "api_key = \"YOUR-CROWDAI-API-KEY-HERE\"\n",
    "challenge = crowdai.Challenge(\"crowdAIMappingChallenge\", api_key)\n",
    "result = challenge.submit(\"predictions.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
